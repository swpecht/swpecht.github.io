use itertools::Itertools;
use rand::{seq::SliceRandom, thread_rng};

use crate::{
    actions,
    algorithms::tabular_best_response::TabularBestResponse,
    cfragent::cfrnode::ActionVec,
    game::{
        kuhn_poker::{KPAction, KPGameState},
        Action, Game, GameState,
    },
    policy::Policy,
};

pub struct ExploitabilityData {
    pub nash_conv: f64,
    pub player_improvements: Vec<f64>,
}

/// Value of a state for every player given a policy.
fn state_values<G: GameState, P: Policy<G>>(
    state: &G,
    num_players: usize,
    policy: &mut P,
) -> Vec<f64> {
    if state.is_terminal() {
        return (0..num_players).map(|p| state.evaluate(p)).collect_vec();
    }

    let actions = actions!(state);
    let probs = match state.is_chance_node() {
        true => uniform_action_probs(&actions),
        false => policy.action_probabilities(state),
    };

    let mut v = vec![0.0; num_players];

    for a in actions {
        let mut ngs = state.clone();
        ngs.apply_action(a);
        let action_values = state_values(&ngs, num_players, policy);
        for p in 0..num_players {
            v[p] += probs[a] * action_values[p];
        }
    }
    v
}

/// Return an action vec of uniform probailities
fn uniform_action_probs(actions: &Vec<Action>) -> ActionVec<f64> {
    let mut v = ActionVec::new(actions);
    let p = 1.0 / actions.len() as f64;

    for &a in actions {
        v[a] = p;
    }

    v
}

/// Returns the exploitability using the nash_conv method from openspeil
///
/// https://github.com/deepmind/open_spiel/blob/master/open_spiel/python/algorithms/exploitability.py
/// See https://arxiv.org/pdf/1711.00832.pdf for the NashConv definition.
pub fn exploitability<G: GameState, P: Policy<G>>(
    game: Game<G>,
    policy: &mut P,
) -> ExploitabilityData {
    let root_state = (game.new)();
    exploitability_from_state(root_state, policy)
}

pub fn exploitability_manual_chance<G: GameState, P: Policy<G>>(
    game: Game<G>,
    policy: &mut P,
) -> f64 {
    let mut root_state = (game.new)();
    let mut chance_outcomes = Vec::new();
    find_chance_outcomes(&mut root_state, &mut chance_outcomes);
    let n = chance_outcomes.len();
    let mut total_exploitability = 0.0;
    for co in chance_outcomes {
        total_exploitability += exploitability_from_state(co, policy).nash_conv;
    }

    total_exploitability / n as f64
}

fn find_chance_outcomes<G: GameState>(gs: &mut G, outcomes: &mut Vec<G>) {
    if !gs.is_chance_node() {
        outcomes.push(gs.clone());
        return;
    }

    for a in actions!(gs) {
        gs.apply_action(a);
        find_chance_outcomes(gs, outcomes);
        gs.undo();
    }
}

fn exploitability_from_state<G: GameState, P: Policy<G>>(
    root_state: G,
    policy: &mut P,
) -> ExploitabilityData {
    if root_state.num_players() != 2 {
        panic!("only support 2 players");
    }

    let mut best_response_values = Vec::new();
    for p in 0..root_state.num_players() {
        let mut br = TabularBestResponse::new(policy, &root_state, p, 0.0);
        best_response_values.push(br.value(&mut root_state.clone()));
    }

    let on_policy_values = state_values(&root_state, root_state.num_players(), policy);
    let mut player_improvements = Vec::new();
    for i in 0..on_policy_values.len() {
        player_improvements.push(best_response_values[i] - on_policy_values[i]);
    }

    let nash_conv = player_improvements.iter().sum();

    ExploitabilityData {
        nash_conv,
        player_improvements,
    }
}

pub struct SampledExploitabilityData {
    pub nash_conv: f64,
    pub iterations: usize,
}

/// Estimates exploitability by choosing randomly at initial chance nodes and averages over the results
pub fn sampled_exploitability<G: GameState, P: Policy<G>>(
    game: Game<G>,
    policy: &mut P,
    iterations: usize,
) -> SampledExploitabilityData {
    let mut nash_conv_sum = 0.0;
    let ngf = game.new;
    let mut rng = thread_rng();
    let mut actions = Vec::new();

    for _ in 0..iterations {
        let mut gs = (ngf)();
        while gs.is_chance_node() {
            actions.clear();
            gs.legal_actions(&mut actions);
            let a = actions.choose(&mut rng).unwrap();
            gs.apply_action(*a);
        }

        nash_conv_sum += exploitability_from_state(gs, policy).nash_conv;
    }

    SampledExploitabilityData {
        nash_conv: nash_conv_sum / iterations as f64,
        iterations,
    }
}

/// Policy for the nash equialibrium strategy of kuhn poker
///
/// https://en.wikipedia.org/wiki/Kuhn_poker
#[derive(Default)]
pub struct KuhnPokerNashPolicy {}
impl Policy<KPGameState> for KuhnPokerNashPolicy {
    fn action_probabilities(&mut self, gs: &KPGameState) -> ActionVec<f64> {
        assert!(!gs.is_chance_node());
        let istate = gs.istate_string(gs.cur_player());
        let bet_rate = match istate.as_str() {
            "Jack" => 1.0 / 3.0,
            "Jackb" => 0.0,
            "Jackp" => 1.0 / 3.0,
            "Jackpb" => 0.0,
            "King" => 1.0,
            "Kingb" => 1.0,
            "Kingp" => 1.0,
            "Kingpb" => 1.0,
            "Kingpbp" => 1.0,
            "Queen" => 0.0,
            "Queenp" => 0.0,
            "Queenpb" => 2.0 / 3.0,
            "Queenb" => 1.0 / 3.0,
            _ => panic!("invalid istate string: {}", istate),
        };

        let mut policy = ActionVec::new(&actions!(gs));

        policy[KPAction::Bet.into()] = bet_rate;
        policy[KPAction::Pass.into()] = 1.0 - bet_rate;

        policy
    }
}

#[cfg(test)]
mod tests {
    use approx::assert_relative_eq;
    use log::info;
    use rand::SeedableRng;

    use crate::{
        algorithms::{
            exploitability::{
                exploitability, exploitability_from_state, exploitability_manual_chance,
                find_chance_outcomes, sampled_exploitability, KuhnPokerNashPolicy,
            },
            ismcts::RandomRolloutEvaluator,
            pimcts::PIMCTSBot,
        },
        game::{
            bluff::{Bluff, BluffActions, Dice},
            kuhn_poker::{KPAction, KuhnPoker},
            GameState,
        },
        policy::{self, AlwaysPolicy, UniformRandomPolicy},
    };

    #[test]
    fn test_always_bet_exploitability() {
        let mut policy = AlwaysPolicy::new(KPAction::Bet.into());
        let data = exploitability(KuhnPoker::game(), &mut policy);

        // With no chance outcomes decided:
        // 1/3 chance get a 0 -- should immediately fold, ev = -1
        // 1/3 chance get a 1 -- should be neutral, 50% of time win and 50% lose, ev = 0
        // 1/3 chance get a 2 -- should bet, 100% win 2
        //
        // Total should be 1/3 * (0 + -1 + 2) = 1/3 for each player
        assert_relative_eq!(data.nash_conv, 2.0 / 3.0)
    }

    #[test]
    fn test_always_fold_exploitability() {
        let mut policy = AlwaysPolicy::new(KPAction::Pass.into());
        let data = exploitability(KuhnPoker::game(), &mut policy);

        // From openspeil tests: https://github.com/deepmind/open_spiel/blob/master/open_spiel/python/algorithms/exploitability_test.py
        assert_relative_eq!(data.nash_conv, 2.0)
    }

    #[test]
    fn test_uniform_exploitability() {
        let mut policy = UniformRandomPolicy::new();
        let data = exploitability(KuhnPoker::game(), &mut policy);
        assert_eq!(data.nash_conv, 11.0 / 12.0)
    }

    #[test]
    fn test_kuhn_poker_nash_exploitability() {
        let mut policy = KuhnPokerNashPolicy::default();
        let data = exploitability(KuhnPoker::game(), &mut policy);
        assert_relative_eq!(data.nash_conv, 0.0);

        let e = exploitability_manual_chance(KuhnPoker::game(), &mut policy);
        assert_relative_eq!(e, 0.0);
    }

    #[test]
    fn test_sample_exploitability_kuhn_poker() {
        let mut policy = KuhnPokerNashPolicy::default();
        let data = exploitability(KuhnPoker::game(), &mut policy);
        let data_sampled = sampled_exploitability(KuhnPoker::game(), &mut policy, 1_000);

        assert_relative_eq!(data_sampled.nash_conv, data.nash_conv);
    }

    #[test]
    fn scratch() {
        let g = Bluff::game(1, 1);

        let mut p = RandomRolloutEvaluator::new(20, SeedableRng::seed_from_u64(42));

        let dice = vec![
            Dice::One,
            Dice::Two,
            Dice::Three,
            Dice::Four,
            Dice::Five,
            Dice::Wild,
        ];

        let mut chance_outcomes = Vec::new();
        for p1 in dice.clone() {
            for p2 in dice.clone() {
                let mut g = Bluff::new_state(1, 1);
                g.apply_action(BluffActions::Roll(p1).into());
                g.apply_action(BluffActions::Roll(p2).into());

                assert!(!g.is_chance_node());
                chance_outcomes.push(g);
            }
        }

        let mut other_outcomes = Vec::new();
        find_chance_outcomes(&mut Bluff::new_state(1, 1), &mut other_outcomes);
        assert_eq!(other_outcomes, chance_outcomes);

        let mut values = Vec::new();
        let mut value_sum = 0.0;
        for g in chance_outcomes {
            let e = exploitability_from_state(g, &mut p).nash_conv;
            value_sum += e;
            values.push(e);
        }

        // for some reason, evaluating each chance node individually is not giving the same sign
        // as the call for the overall chance node evaluation
        // why is the wtd avg value of the chance node exploitability, not the same as the overall exploitability?
        // Also is this a way to calculate the exploitability with significantly less memory? Only run the exploitability calc on the
        // chance nodes, one at a time and then sum the results

        // Seeing different results between manual exploitability and doing it in this test. Why?

        let sum: f64 = values.iter().sum();
        assert!(sum > 0.0);
        assert_eq!(sum, value_sum);
        let manual = exploitability_manual_chance(g.clone(), &mut p);
        assert_eq!(value_sum / values.len() as f64, manual);

        let calculated = exploitability(g, &mut p).nash_conv;
        assert_eq!(sum, calculated);

        todo!()
    }
}
